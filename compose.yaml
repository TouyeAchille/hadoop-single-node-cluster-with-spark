name: hadoop-spark 
services:
  hadoop-single-node:
    build: .
    ports:
      - 9870:9870       # HDFS NameNode UI
      - 8088:8088       # YARN ResourceManager UI
      - 8080:8080       # Spark Master UI
      - 7077:7077       # Spark Master Port
      - 8888:8888       # Jupyter Notebook  
    environment:
      - HADOOP_HOME=/usr/local/hadoop
      - SPARK_HOME=/usr/local/spark
      - JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
      - HADOOP_CONF_DIR=${HADOOP_HOME}/hadoop/etc/hadoop
      - PATH=${HADOOP_HOME}/hadoop/bin:${HADOOP_HOME}/hadoop/sbin:${SPARK_HOME}/spark/bin:${SPARK_HOME}/spark/sbin:$PATH
      - HADOOP_MAPRED_HOME=$HADOOP_HOME 
      - HADOOP_COMMON_HOME=$HADOOP_HOME 
      - HADOOP_HDFS_HOME=$HADOOP_HOME
      - HADOOP_YARN_HOME=$HADOOP_HOME 
      - HADOOP_TOOLS_HOME=$HADOOP_HOME 
      - HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/hadoop/lib/native
    container_name: hadoop-single-node
    hostname: hadoop-single-node
    stdin_open: true
    tty: true
    ulimits:
      nofile:
        soft: 1024
        hard: 1024
    volumes:
      - notebooks:/root/notebooks
    command: >
      sh -c "service ssh start && bash"

volumes:
  notebooks:
